{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR 2020:][iapr2020] Lab 1 â€’  Image segmentation\n",
    "\n",
    "**Author:** Sven Borden, Artur Jesslen and Sorya Jullien  \n",
    "**Due date:** 26.03.2020\n",
    "\n",
    "[iapr2018]: https://github.com/LTS5/iapr-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract relevant data\n",
    "We first need to extract the `lab-01-data.tar.gz` archive.\n",
    "To this end, we use the [tarfile] module from the Python standard library.\n",
    "\n",
    "[tarfile]: https://docs.python.org/3.6/library/tarfile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "data_folder = 'lab-01-data'\n",
    "tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "    tar.extractall(path = data_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.morphology as morph\n",
    "import skimage.filters as filt\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "from scipy import signal\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Brain segmentation\n",
    "\n",
    "Your goal: compute the size of the brain (in pixels) in a 2D image of a human head taken by Magnetic Resonance Imaging (MRI).\n",
    "* Try as many methods as you can, the more the better.\n",
    "* At least region growing and contour detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Brain image visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load image\n",
    "data_path = os.path.join(data_base_path, data_folder)\n",
    "brain_im = skimage.io.imread(os.path.join(data_path, 'brain-slice40.tiff'))\n",
    "im_h, im_w = brain_im.shape\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.imshow(brain_im, cmap='gray')\n",
    "ax.set_title('MRI brain image ({} px, {} px)'.format(im_h, im_w))\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Region growing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seed selection + initilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = brain_im.copy()\n",
    "\n",
    "# create empty region map\n",
    "region = np.zeros([im_w,im_h],dtype=np.uint8)\n",
    "\n",
    "# Seed selection\n",
    "current_pix = (int(im_h/2), int(im_w/2)+50)\n",
    "\n",
    "# Parameters\n",
    "mean_region = float(img[current_pix[1], current_pix[0]])\n",
    "size = 1\n",
    "pixel_area = im_h * im_w\n",
    "\n",
    "contour = []\n",
    "contour_value = []\n",
    "dist = 0\n",
    "\n",
    "threshold = 20\n",
    "\n",
    "## Using 4-connectivity \n",
    "connectivity = [(1, 0), (0, 1), (-1, 0), (0, -1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Growing procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homogeinity condition is that the difference between pixels need to be smaller than a given threshold \n",
    "while (size < pixel_area) and (dist < threshold):\n",
    "    ## add pixels\n",
    "    for i in range(len(connectivity)):\n",
    "        # For each pixel of the connectivity patern\n",
    "        temp_pix = [current_pix[0] + connectivity[i][0], current_pix[1] + connectivity[i][1]]\n",
    "        \n",
    "        # check if it belongs to image\n",
    "        belong_img = (im_h > temp_pix[0] > 0) and (im_w > temp_pix[1] > 0)\n",
    "\n",
    "        # check that it wasn't selected before\n",
    "        if(belong_img and (region[temp_pix[1], temp_pix[0]] == 0)):\n",
    "            contour.append(temp_pix)\n",
    "            contour_value.append(img[temp_pix[1], temp_pix[0]])\n",
    "            region[temp_pix[1], temp_pix[0]] = 150\n",
    "    \n",
    "    # add the nearest pixel of the contour in it\n",
    "    dist_list = [abs(j - mean_region) for j in contour_value ]\n",
    "    \n",
    "    dist = min(dist_list)\n",
    "    index = dist_list.index(min(dist_list))\n",
    "    size += 1\n",
    "    region[current_pix[1], current_pix[0]] = 255\n",
    "    \n",
    "    mean_region = (mean_region * size + float(contour_value[index]))/(size+1)\n",
    "    \n",
    "    # update seed\n",
    "    current_pix = contour[index]\n",
    "    \n",
    "    del contour[index]\n",
    "    del contour_value[index]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Morphological operation on the region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_morph = morph.binary_closing(region, selem=morph.disk(radius = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10,10))\n",
    "fig.suptitle('Brain segmentation')\n",
    "axs[0,0].imshow(region)\n",
    "axs[0,0].set_title('raw region')\n",
    "axs[0,1].imshow(region_morph)\n",
    "axs[0,1].set_title('morphological region')\n",
    "axs[1,0].imshow(brain_im, cmap=\"gray\")\n",
    "axs[1,0].imshow(region, alpha=0.5)\n",
    "axs[1,0].set_title('raw region visualized')\n",
    "axs[1,1].imshow(brain_im, cmap=\"gray\")\n",
    "axs[1,1].imshow(region_morph, alpha=0.5)\n",
    "axs[1,1].set_title('morphological region visualized')\n",
    "axs[0,0].axis('off')\n",
    "axs[1,0].axis('off')\n",
    "axs[0,1].axis('off')\n",
    "axs[1,1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Size computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_area_raw = np.count_nonzero(region)\n",
    "brain_area_morph = np.count_nonzero(region_morph)\n",
    "print('Raw brain area : {:d}px ({:.2f}%)\\nMorph brain area: {:d}px ({:.2f}%)'.format(brain_area_raw, brain_area_raw/pixel_area*100, brain_area_morph, brain_area_morph/pixel_area*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know the brain is roughly a circle, so we can approximate the height and width by the diameter of the circle, which we can relate to the area of the disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_diameter_raw = 2*np.sqrt(brain_area_raw/np.pi)\n",
    "brain_diameter_morph = 2*np.sqrt(brain_area_morph/np.pi)\n",
    "print('Raw brain diameter : {:.2f}px\\nMorph brain diameter : {:.2f}px'.format(brain_diameter_raw, brain_diameter_morph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Contour detection\n",
    "Edge detection using **Marr-Hilderth** algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Laplacian of gaussian using mathematical expression (sum of second derivative of gaussian)\n",
    "def LoG(x, y, sigma):\n",
    "    return - (2 - (x**2 + y**2) / (sigma**2))*np.exp(-(x**2+y**2)/(2*sigma**2))/(np.sqrt(2*np.pi)*sigma**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a kernel with adapted size (as function of sigma) of the laplacian of gaussian\n",
    "def LoG_kernel(sigma = 1):\n",
    "    size = int(2*(np.ceil(3*sigma))+1)\n",
    "    x, y = np.meshgrid(np.arange(-size/2, size/2+1), np.arange(-size/2, size/2+1))\n",
    "    return LoG(x, y, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the zero crossing algorithm\n",
    "def zero_crossing(image):\n",
    "    zero_crossing = np.zeros_like(image)\n",
    "    image = image.astype(np.int64)\n",
    "    # computing zero_crossing\n",
    "    for i in range(image.shape[0]-1):\n",
    "        for j in range(image.shape[1]-1):\n",
    "            # For each zero pixel, its neighbohood must contain a positive AND a negative value to be a zero crossing\n",
    "            if image[i][j] == 0:\n",
    "                if (image[i][j-1] < 0 and image[i][j+1] > 0) or (image[i][j-1] < 0 and image[i][j+1] < 0) or (image[i-1][j] < 0 and image[i+1][j] > 0) or (image[i-1][j] > 0 and image[i+1][j] < 0):\n",
    "                    zero_crossing[i][j] = 255\n",
    "            # For each negative pixel, its neighbohood must contain a positive value to be a zero crossing \n",
    "            if image[i][j] < 0:\n",
    "                if (image[i][j-1] > 0) or (image[i][j+1] > 0) or (image[i-1][j] > 0) or (image[i+1][j] > 0):\n",
    "                    zero_crossing[i][j] = 255\n",
    "    return zero_crossing\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 2\n",
    "# Using 2 methods to compare\n",
    "# First method : Canny edge (given in the cv2 library)\n",
    "contoured = cv2.Canny(brain_im, 100, 200)\n",
    "# Second method : Convolution of laplacian of gaussian kernel with image\n",
    "# followed by the zero crossing algorithm to find the edges\n",
    "laplacGauss = LoG_kernel(sigma)\n",
    "contoured2 = signal.convolve(brain_im, laplacGauss, mode='same')\n",
    "contoured2_zc = zero_crossing(contoured2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(15, 15))\n",
    "ax[0,0].imshow(brain_im, cmap='gray')\n",
    "ax[0,0].set_title('MRI brain image ({} px, {} px)'.format(im_h, im_w))\n",
    "ax[0,0].axis('off')\n",
    "ax[0,1].imshow(contoured, cmap='gray')\n",
    "ax[0,1].set_title('Canny edges (cv2 library) ({} px, {} px)'.format(im_h, im_w))\n",
    "ax[0,1].axis('off')\n",
    "ax[1,0].imshow(contoured2, cmap='gray')\n",
    "ax[1,0].set_title('Laplacian of Gaussian convolved with image (sigma = {:d}) ({} px, {} px)'.format(sigma, im_h, im_w))\n",
    "ax[1,0].axis('off')\n",
    "ax[1,1].imshow(contoured2_zc, cmap='gray')\n",
    "ax[1,1].set_title('Zero crossing applied on LoG image ({} px, {} px)'.format(im_h, im_w))\n",
    "ax[1,1].axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see on the previous images, the Marr-Hilderth algorithm is very powerful to show the edges.  \n",
    "Some edges are better represented by the Marr-Hilderth algorithm compared to the Canny edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Additional method(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simpler version for brain detection using only a threshold followed by mathematical morphology operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold function\n",
    "def threshold(img, th1 = None, th2 = None):\n",
    "    out = np.ones(np.shape(img))\n",
    "    if th1 is not None:\n",
    "        out[np.where(img < th1)] = 0\n",
    "    if th2 is not None:\n",
    "        out[np.where(img > th2)] = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding operation\n",
    "img_threshold = threshold(brain_im, 60, 100)\n",
    "\n",
    "# Mathematical morphology\n",
    "img_morph = morph.binary_opening(img_threshold, selem=morph.disk(3))\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 15))\n",
    "ax[0].imshow(img_threshold)\n",
    "ax[0].set_title('MRI brain image ({} px, {} px)'.format(im_h, im_w))\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(img_morph)\n",
    "ax[1].set_title('MRI brain image ({} px, {} px)'.format(im_h, im_w))\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(brain_im, cmap=\"gray\")\n",
    "ax[2].imshow(img_morph, alpha=0.5)\n",
    "ax[2].set_title('morphological region visualized')\n",
    "ax[2].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use some simple morphological operators and a threshold to detect the brain part on the image. It needs a lot less computation than the the growing algorithm but is not as powerful. For a lot of application, this method is sufficiently precise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Shape/color segmentation\n",
    "\n",
    "You will find hereafter three pictures taken under three different illuminations, containing some shapes with different colors. We ask you to create a routine to:\n",
    "\n",
    "1. Count the number of shapes of each color.\n",
    "2. Compute the total area (in pixels) of each color.\n",
    "\n",
    "Please note that one specific challenge is to be robust to illumination changes. Therefore some kind of intensity normalization should probably be used.\n",
    "\n",
    "**Note:** the routine(s) that you will write for this exercise will be useful for the final project as well, so pay special attention to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "im_names = ['arena-shapes-01', 'arena-shapes-02', 'arena-shapes-03']\n",
    "filenames = [os.path.join(data_path, name) + '.png' for name in im_names]\n",
    "ic = skimage.io.imread_collection(filenames)\n",
    "images = skimage.io.concatenate_images(ic)\n",
    "print('Number of images: ', images.shape[0])\n",
    "print('Image size: {}, {} '.format(images.shape[1], images.shape[2]))\n",
    "print('Number of color channels: ', images.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 12))\n",
    "for ax, im, nm in zip(axes.ravel(), images, im_names):\n",
    "    ax.imshow(im)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(img):\n",
    "    _min = img.min()\n",
    "    _max = img.max()\n",
    "    return img - _min / (_max - _min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing a threshold to isolate foreground from foreground\n",
    "images_gray = np.zeros((images.shape[0], images.shape[1], images.shape[2]))\n",
    "images_threshold = np.zeros(images_gray.shape)\n",
    "for i in range(images.shape[0]):\n",
    "    images_gray[i,:,:] = rgb2gray(images[i,:,:,:])\n",
    "    # We are using an adaptative threshold that find the best threshold depeding of the illumination\n",
    "    t = filt.threshold_otsu(images_gray[i,:,:])\n",
    "    images_threshold[i,:,:] = threshold(images_gray[i,:,:], t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 12))\n",
    "for ax, im, nm in zip(axes.ravel(), images_threshold, im_names):\n",
    "    ax.imshow(im)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Number of shapes of each color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a neighbor has label, if yes, it will return the label\n",
    "def check(list, val): \n",
    "    # traverse in the list \n",
    "    for x_list in list: \n",
    "        # compare with all the values \n",
    "        # with val \n",
    "        if val > x_list and x_list > 0: \n",
    "            return x_list \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return an image with element corresponding to the given label\n",
    "def labeling(img, label):\n",
    "    out = np.zeros(np.shape(img), dtype = np.uint)\n",
    "    out[np.where(img == label)] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 12))\n",
    "labels = []\n",
    "# Iterating on every images\n",
    "for ax, image_thres, name in zip(axes.ravel(), images_threshold, im_names):\n",
    "    new_label = 1\n",
    "    im_h = image_thres.shape[0] \n",
    "    im_w = image_thres.shape[1]\n",
    "\n",
    "    label = np.zeros(image_thres.shape, dtype=np.uint)\n",
    "    \n",
    "    # Iterating on each pixels of the image\n",
    "    for i in range(1, im_h-1):\n",
    "        for j in range(1, im_w-1):\n",
    "            # Labeling each pixels of the foreground with same value as its neighbor\n",
    "            if image_thres[i,j] == 0:\n",
    "                label_neighbors = np.max([label[i-1,j+1], label[i-1,j-1], \n",
    "                                          label[i-1,j], label[i,j-1]])\n",
    "                if label_neighbors != 0:\n",
    "                    label[i,j] = label_neighbors\n",
    "                else:\n",
    "                    label[i,j] = new_label+1\n",
    "                    new_label += 1\n",
    "                    \n",
    "    # Merging of labels for objects that are containing different labels\n",
    "    label2 = label\n",
    "    for i in range(1, im_h-1):\n",
    "        for j in range(1, im_w-1):\n",
    "            label_neighbors = [label2[i-1,j+1], label2[i,j+1], \n",
    "                               label2[i+1,j+1], label2[i-1,j], \n",
    "                               label2[i+1,j], label2[i-1,j-1], \n",
    "                               label2[i,j-1], label2[i+1,j-1]]\n",
    "            val_min = check(label_neighbors,label2[i,j])\n",
    "            if check(label_neighbors,label2[i,j]):\n",
    "                label2[np.where(label2 == label2[i,j])] = val_min\n",
    "\n",
    "    ax.imshow(label2)\n",
    "    ax.set_title(name)\n",
    "    labels.append(label2)\n",
    "\n",
    "    label_unique = np.unique(label2)\n",
    "    # Background is not an object so we subtract 1\n",
    "    nb_objects = len(label_unique) - 1\n",
    "\n",
    "    print('{} : There are {:d} objects.'.format(name, nb_objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_class = []\n",
    "for image, label, name in zip(images, labels, im_names):\n",
    "    # count nb of objects of different colors\n",
    "    object_color = np.zeros((nb_objects, images.shape[-1]))\n",
    "    \n",
    "    # Define biggest difference beteween colors\n",
    "    other_class_idx = 0\n",
    "    \n",
    "    for i in range(nb_objects):\n",
    "        # Define an image with colors of objects\n",
    "        object_colored = np.array(labeling(label, np.unique(label)[i+1]))[:,:,None]*np.array(image)\n",
    "        \n",
    "        # Define mean color of object\n",
    "        for channel in range(images.shape[-1]):\n",
    "            object_color[i, channel] = object_colored[object_colored[:,:,channel] != 0, channel].mean()\n",
    "\n",
    "    # Classification of colors using kmeans algorithm\n",
    "    kmeans = KMeans(n_clusters=2).fit(object_color)\n",
    "    object_class.append(kmeans.labels_)\n",
    "    \n",
    "    print('{} : There are {} shapes of color 1.\\n                  There are {} shapes of color 2.'.format(name,len(kmeans.labels_)-np.count_nonzero(kmeans.labels_),np.count_nonzero(kmeans.labels_)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Total area (in pixels) of each color\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_pixels = im_h*im_w\n",
    "for label_matrix, name, obj_class in zip(labels, im_names, object_class):\n",
    "    nb_pixels1 = 0\n",
    "    nb_pixels2 = 0\n",
    "\n",
    "    for i in range(nb_objects):\n",
    "        # Find where pixels of objects are\n",
    "        obj = labeling(label, np.unique(label)[i+1])\n",
    "        if obj_class[i] == 0:\n",
    "            nb_pixels1 += obj.sum()\n",
    "        else:\n",
    "            nb_pixels2 += obj.sum()\n",
    "\n",
    "    print('{} : Color 1 area : {:d}px ({:.2f}% of the image)\\n                  Color 2 area : {:d}px ({:.2f}% of the image)'.format(name, int(nb_pixels1), nb_pixels1/total_pixels*100, int(nb_pixels2), nb_pixels2/total_pixels*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
