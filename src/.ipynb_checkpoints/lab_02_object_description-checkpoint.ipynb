{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR 2020:][iapr2020] Lab 2 ‒  Object description\n",
    "\n",
    "**Authors:** Sven Borden, Sorya Jullien, Artur Jesslen  \n",
    "**Due date:** 24.04.2020\n",
    "\n",
    "[iapr2020]: https://github.com/LTS5/iapr-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before running this notebook, verify that you have all requirements by running this command in your terminal:\n",
    "`pip install numpy opencv-python matplotlib mlxtend scikit-learn scikit-image`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Be sure to have `wagner_fisher.py` file in the src directory\n",
    "It can be find in the moodle assignement or following this [link][gist].\n",
    "\n",
    "[gist]: https://gist.github.com/kylebgorman/8034009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wagner_fisher as wf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract relevant data\n",
    "We first need to extract the `lab-02-data.tar.gz` archive.\n",
    "To this end, we use the [tarfile] module from the Python standard library.\n",
    "\n",
    "[tarfile]: https://docs.python.org/3.6/library/tarfile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import wagner_fisher as wf\n",
    "import warnings\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "warnings.filterwarnings(\"ignore\",category=plt.cbook.mplDeprecation)\n",
    "\n",
    "\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "data_folder = 'lab-02-data'\n",
    "tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "    tar.extractall(path=data_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "In the `lab-02-data/part1` folder, you will find 28x28 grey-scale pictures of handwritten \"0\" and \"1\".\n",
    "These digits have been extracted from MNIST dataset (http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "Your goal is to extract, from each of those images, a 2-dimensional feature vector (i.e. 2 features) and to plot them all on a 2D graph.\n",
    "If you have chosen good features, the vectors of the \"0\"'s should nicely cluster in one part of the plane and those of the \"1\"'s in another.\n",
    "\n",
    "Please try first the Fourier Descriptors.\n",
    "You can make several attempts: e.g. with and without invariance to rotation, translation, scaling, etc.\n",
    "You can also for instance rotate the images and assess the invariance in rotation.\n",
    "\n",
    "**Note:** for the Fourier descriptors, the u_k signal has to be constructed by following the contour point after point.\n",
    "Some pre-processing (image binarization, possibly some Mathematical Morphology) might be useful.\n",
    "\n",
    "Then feel free to try other features, the more you try, the better it will be (for you)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load images\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "data_folder = 'lab-02-data'\n",
    "\n",
    "#  Load zeros\n",
    "zeros_path = os.path.join(data_base_path, data_folder, 'part1', '0')\n",
    "zeros_names = [nm for nm in os.listdir(zeros_path) if '.png' in nm]  # make sure to only load .png\n",
    "zeros_names.sort()  # sort file names\n",
    "ic = skimage.io.imread_collection([os.path.join(zeros_path, nm) for nm in zeros_names])\n",
    "\n",
    "zeros_im = skimage.io.concatenate_images(ic)\n",
    "zeros_thresholded_tmp = [cv2.threshold(img.copy(), 2, 1, cv2.THRESH_BINARY) for img in zeros_im]\n",
    "zeros_thresholded = [threshold for _, threshold in zeros_thresholded_tmp]\n",
    "del zeros_thresholded_tmp\n",
    "\n",
    "\n",
    "#  Load ones\n",
    "ones_path = os.path.join(data_base_path, data_folder, 'part1', '1')\n",
    "ones_names = [nm for nm in os.listdir(ones_path) if '.png' in nm]  # make sure to only load .png\n",
    "ones_names.sort()  # sort file names\n",
    "ic = skimage.io.imread_collection(([os.path.join(ones_path, nm) for nm in ones_names]))\n",
    "\n",
    "ones_im = skimage.io.concatenate_images(ic)\n",
    "ones_thresholded_tmp = [cv2.threshold(img.copy(), 2, 1, cv2.THRESH_BINARY) for img in ones_im]\n",
    "ones_thresholded = [threshold for _, threshold in ones_thresholded_tmp]\n",
    "del ones_thresholded_tmp\n",
    "\n",
    "\n",
    "# Plot images\n",
    "fig, axes = plt.subplots(2, len(zeros_im), figsize=(12, 3))\n",
    "for ax, im, nm in zip(axes[0], zeros_im, zeros_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "for ax, im, nm in zip(axes[1], ones_im, ones_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Fourier descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find descriptors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CONTOUR_POINT = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contour(img, opencv_version):\n",
    "    \"\"\" Finds and returns the contour of the image\"\"\"\n",
    "    contour = []\n",
    "    if int(opencv_version) == 3:\n",
    "        _, contour, _ = cv2.findContours(img, mode = cv2.RETR_TREE, method = cv2.CHAIN_APPROX_NONE)\n",
    "    else:\n",
    "        contour, _ = cv2.findContours(img.copy(), mode = cv2.RETR_TREE, method = cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    contour_array = contour[0].reshape(-1, 2)\n",
    "    if contour_array.shape[0] < MIN_CONTOUR_POINT:\n",
    "        contour_array = contour[1].reshape(-1, 2)\n",
    "    return contour_array\n",
    "\n",
    "def convert_contour(contour):\n",
    "    contour_complex = np.empty(contour.shape[:-1], dtype=complex)\n",
    "    contour_complex.real = contour[:, 0]\n",
    "    contour_complex.imag = contour[:, 1]\n",
    "    return contour_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_descriptor(contour):\n",
    "    \"\"\" Finds and returns the Fourier-Descriptor from the image contour\"\"\"\n",
    "    return np.fft.fft(contour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store version of opencv to adapt the method used\n",
    "opencv_version, opencv_version_minor, _ = cv2.__version__.split(\".\")\n",
    "print('OpenCV Version: {}.{}'.format(opencv_version, opencv_version_minor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_contours = []\n",
    "one_contours = []\n",
    "\n",
    "zero_descriptors = []\n",
    "one_descriptors = []\n",
    "\n",
    "for zero_img, one_img in zip(zeros_thresholded, ones_thresholded):\n",
    "    contour0_raw = find_contour(zero_img, opencv_version)\n",
    "    contour0_complex = convert_contour(contour0_raw)\n",
    "    descriptor0 = find_descriptor(contour0_complex)\n",
    "    \n",
    "    contour1_raw = find_contour(one_img, opencv_version)\n",
    "    contour1_complex = convert_contour(contour1_raw)\n",
    "    descriptor1 = find_descriptor(contour1_complex)\n",
    "    \n",
    "    # Save for later usage\n",
    "    zero_contours.append(contour0_raw)\n",
    "    one_contours.append(contour1_raw)\n",
    "    zero_descriptors.append(descriptor0)\n",
    "    one_descriptors.append(descriptor1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot contours \n",
    "fig, axes = plt.subplots(2, len(zeros_im), figsize=(12, 3))\n",
    "for ax, im, nm, cont in zip(axes[0], zeros_im, zeros_names, zero_contours):\n",
    "    ax.scatter(cont[:, 0], cont[:, 1])\n",
    "    ax.set_xlim(0, 28)\n",
    "    ax.set_ylim(0, 28)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "for ax, im, nm, cont in zip(axes[1], ones_im, ones_names, one_contours):\n",
    "    ax.scatter(cont[:, 0], cont[:, 1], marker=',')\n",
    "    ax.set_xlim(0, 28)\n",
    "    ax.set_ylim(0, 28)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_coeff = 2\n",
    "zeros_coeff = []\n",
    "ones_coeff = []\n",
    "\n",
    "for zero_descriptor, one_descriptor in zip(zero_descriptors, one_descriptors):\n",
    "    zeros_coeff.append(np.absolute(zero_descriptor[1:nb_coeff+1]))\n",
    "    ones_coeff.append(np.absolute(one_descriptor[1:nb_coeff+1]))\n",
    "\n",
    "plt.scatter(np.asarray(zeros_coeff)[:,0], np.asarray(zeros_coeff)[:,1], color='red', label='zeros descriptors')\n",
    "plt.scatter(np.asarray(ones_coeff)[:,0], np.asarray(ones_coeff)[:,1], color='blue', label='ones descriptors')   \n",
    "plt.xlabel(\"Fourrier coefficient 1\")\n",
    "plt.ylabel(\"Fourrier coefficient 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that when we project the 0 and 1 images using the space of the magnitude of the descriptors 1 and 2, we can linearly separate our data!  \n",
    "Moreover, it is invariant to translation (dependant of descriptor 0) and to rotation (change only phase)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification\n",
    "To classify zeros and ones, we will use SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training dataset from the two fourrier coefficients\n",
    "x_train = np.concatenate((zeros_coeff, ones_coeff), axis=0)\n",
    "y_train = np.concatenate((np.zeros(len(zeros_coeff), dtype=int), np.ones(len(ones_coeff), dtype=int)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "classifier = SVC(kernel='linear')\n",
    "classifier.fit(x_train, y_train)\n",
    "supports = classifier.support_vectors_\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(supports[:,0], supports[:,1], marker=\"$\\u25EF$\",linewidth='1', s=200, edgecolors='green', label='Support Vectors')\n",
    "plot_decision_regions(x_train, y_train, clf=classifier, legend=2)\n",
    "plt.xlabel(\"Fourrier coefficient 1\")\n",
    "plt.ylabel(\"Fourrier coefficient 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeman/Chain Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_direction = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(angle, nb_direction):\n",
    "    modulo_angle = 360 // nb_direction\n",
    "    angle_direction = np.linspace(-180, 180, nb_direction+1)\n",
    "    return np.abs(angle_direction - angle).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_freeman_code(contour, nb_direction):\n",
    "    \"\"\"Create freeman code (string containing integer character) and differentia freeman code from given image\"\"\"\n",
    "    code = \"\"\n",
    "    diffCode = \"\"\n",
    "    # Compute code\n",
    "    for i in range(contour.shape[0]-1):\n",
    "        next_dir = contour[i+1] - contour[i]\n",
    "        # in degrees\n",
    "        angle = math.atan2(next_dir[1], next_dir[0]) * 180 / math.pi\n",
    "        code += str(get_code(angle, nb_direction))\n",
    "    \n",
    "    # Compute differential code\n",
    "    for i in range(len(code)-1):\n",
    "        new_code = str((int(code[i+1]) - int(code[i]) + nb_direction) % nb_direction)\n",
    "        diffCode += new_code\n",
    "    \n",
    "    return code, diffCode\n",
    "\n",
    "def calculate_distance(code1, code2):\n",
    "    return wf.WagnerFischer(code1, code2).cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_freeman_codes = []\n",
    "one_freeman_codes = []\n",
    "\n",
    "\n",
    "for contour0, contour1 in zip(zero_contours, one_contours):\n",
    "    zero_freeman_codes.append(create_freeman_code(contour0, nb_direction))\n",
    "    one_freeman_codes.append(create_freeman_code(contour1, nb_direction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display results of distance between freeman codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distance_map(img, contour):\n",
    "    \"\"\"Create distance map from binary image\"\"\"\n",
    "    if len(np.shape(contour)) > 2:\n",
    "        raise NameError('One image contour expected only.')    \n",
    "    \n",
    "    # Initialization \n",
    "    out = np.full(img.shape, np.inf)\n",
    "    for i in range(len (contour)):\n",
    "        out[contour[i][0]][contour[i][1]] = 0 #contours = 0\n",
    "    \n",
    "    # Direct passage\n",
    "    for i in range(1, out.shape[0]-1):\n",
    "        for j in range(1, out.shape[1]-1):\n",
    "            out[i, j] = np.array([out[i-1, j-1] + 4, out[i-1, j] + 3, out[i-1, j+1] + 4, out[i, j-1] + 3, out[i, j]]).min()\n",
    "    \n",
    "    # Inverse passage \n",
    "    for i in range(out.shape[0]-2, 0, -1):\n",
    "        for j in range(out.shape[1]-2, 0, -1):\n",
    "            out[i, j] = np.array([out[i, j+1] + 3, out[i+1, j-1] + 4, out[i+1, j] + 3, out[i+1, j+1] + 4, out[i, j]]).min()  \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dist(contour, dist_map):\n",
    "    \"\"\"Compute distance between a binary image and another image using its distance map\"\"\"\n",
    "    if len(np.shape(contour)) > 2:\n",
    "        raise NameError('One image contour expected only.')\n",
    "        \n",
    "    dist = 0\n",
    "    for i in range(contour.shape[0]):\n",
    "        dist += dist_map[contour[i][0],contour[i][1]] \n",
    "    \n",
    "    return dist/contour.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_distance_map = [create_distance_map(img, contour) for img, contour in zip(zeros_thresholded, zero_contours)]\n",
    "ones_distance_map = [create_distance_map(img, contour) for img, contour in zip(ones_thresholded, one_contours)]\n",
    "\n",
    "fig, axes = plt.subplots(2, len(zeros_distance_map), figsize=(17, 4))\n",
    "fig.suptitle(\"Distance map\")\n",
    "for ax, im, nm in zip(axes[0], zeros_distance_map, zeros_names):\n",
    "    ax.imshow(im)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "for ax, im, nm in zip(axes[1], ones_distance_map, ones_names):\n",
    "    ax.imshow(im)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_dist_map = zeros_distance_map[0]\n",
    "one_dist_map = ones_distance_map[0]\n",
    "\n",
    "zeros_dist = []\n",
    "ones_dist = []\n",
    "print(\"Calculating distance for each zero image and associating to its nearest class:\")\n",
    "for i in range(1, len(zeros_distance_map)):\n",
    "    dist_to_zero = compute_dist(zero_contours[i], zero_dist_map)\n",
    "    dist_to_one = compute_dist(zero_contours[i], one_dist_map)\n",
    "    zeros_dist.append(dist_to_zero)\n",
    "    zeros_dist.append(dist_to_one)\n",
    "    print('Image {}: Contour closer to image of type {}'.format(zeros_names[i], 0 if dist_to_zero < dist_to_one else 1))\n",
    "    print('-------------> Distance to 0: {:.02f}, distance to 1: {:.02f}'.format(dist_to_zero, dist_to_one))\n",
    "\n",
    "print(\"\\nCalculating distance for each zero image and associating to its nearest class:\")\n",
    "for i in range(1, len(zeros_distance_map)):\n",
    "    dist_to_zero = compute_dist(one_contours[i], zero_dist_map)\n",
    "    dist_to_one = compute_dist(one_contours[i], one_dist_map)\n",
    "    ones_dist.append(dist_to_zero)\n",
    "    ones_dist.append(dist_to_one)\n",
    "    print('Image {}: Contour closer to image of type {}'.format(ones_names[i], 0 if dist_to_zero < dist_to_one else 1))\n",
    "    print('-------------> Distance to 0: {:.02f}, distance to 1: {:.02f}'.format(dist_to_zero, dist_to_one))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.scatter(range(1,10), np.asarray(zeros_dist[::2]))\n",
    "plt.scatter(range(1,10), np.asarray(zeros_dist[1::2]))\n",
    "plt.legend(['0 (true)', '1 (false)'])\n",
    "plt.xlabel('Image number')\n",
    "plt.ylabel('Distance')\n",
    "plt.subplot(122)\n",
    "plt.scatter(range(1,10), np.asarray(ones_dist[::2]))\n",
    "plt.scatter(range(1,10), np.asarray(ones_dist[1::2]))\n",
    "plt.legend(['0 (false)', '1 (true)'])\n",
    "plt.xlabel('Image number')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using translation and rotation to find closest class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation of image\n",
    "def contour_translation(contour, trans_x, trans_y):\n",
    "    translation_vect = [[trans_x],[trans_y]]\n",
    "    translation_mat = np.repeat(translation_vect, len(contour), axis=1)\n",
    "    translation_mat = translation_mat.transpose()\n",
    "    \n",
    "    #addition\n",
    "    translated_contours = np.add(contour, translation_mat)\n",
    "    \n",
    "    #check if in bounds\n",
    "    up_limit = 28\n",
    "    idx = np.where(translated_contours >= up_limit)\n",
    "    translated_contours = np.delete(translated_contours, idx[0], axis=0)\n",
    "    low_limit = 0\n",
    "    idx = np.where(translated_contours < low_limit)\n",
    "    translated_contours = np.delete(translated_contours, idx[0], axis=0)\n",
    "    \n",
    "    return translated_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation of image\n",
    "def contour_rotation(contour, angle, center):\n",
    "\n",
    "    angle = angle * np.pi / 180 # degrees to radians\n",
    "    rotated_contours = np.zeros(contour.shape, dtype = np.uint)\n",
    "    ox, oy = center\n",
    "    for i in range(contour.shape[0]):       \n",
    "        px, py = contour[i, :]\n",
    "        #+0.5 is to take the closest integer when approximating\n",
    "        rotated_contours[i,0] = int(ox + math.cos(angle) * (px - ox) - math.sin(angle) * (py - oy) + 0.5)\n",
    "        rotated_contours[i,1] = int(oy + math.sin(angle) * (px - ox) + math.cos(angle) * (py - oy) + 0.5)\n",
    "\n",
    "    #check if in bounds\n",
    "    up_limit = 28\n",
    "    idx = np.where(rotated_contours >= up_limit)\n",
    "    rotated_contours = np.delete(rotated_contours, idx[0], axis=0)\n",
    "    low_limit = 0\n",
    "    idx = np.where(rotated_contours < low_limit)\n",
    "    rotated_contours = np.delete(rotated_contours, idx[0], axis=0)\n",
    "  \n",
    "    return rotated_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_btw_zero_t_r = []\n",
    "\n",
    "# optimal translation for the zero images\n",
    "fig, ax = plt.subplots(1, len(zeros_distance_map), figsize=(12, 3))\n",
    "ax[0].imshow(zeros_thresholded[0])\n",
    "ax[0].axis('off')\n",
    "scale = 1\n",
    "for i in range(1, len(zeros_distance_map)):\n",
    "    height, width = zeros_thresholded[i].shape\n",
    "    dist_final = np.inf\n",
    "    x_final = 0\n",
    "    y_final = 0\n",
    "    angle_final = 0\n",
    "    center = (width // 2, height // 2)\n",
    "    \n",
    "    for trans_x in range(-4,5,1):        \n",
    "        for trans_y in range(-4,5,1):\n",
    "            \n",
    "            cnt_translation = contour_translation(zero_contours[i], trans_x, trans_y)\n",
    "            \n",
    "            for angle in np.arange(0, 360, 15):\n",
    "                \n",
    "                cnt_rotation = contour_rotation(cnt_translation, angle, center)\n",
    "                dist2 = compute_dist(cnt_rotation, zero_dist_map)\n",
    "                if dist2 < dist_final:\n",
    "                    dist_final = dist2\n",
    "                    x_final = trans_x\n",
    "                    y_final = trans_y\n",
    "                    angle_final = angle\n",
    "    \n",
    "    distance_btw_zero_t_r.append(dist_final)\n",
    "    translation_matrix = np.float32([[1,0,x_final], [0,1,y_final]])\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, -angle_final, scale)\n",
    "    img_translation = cv2.warpAffine(zeros_thresholded[i], translation_matrix, (width, height))\n",
    "    img_translated_rotated = cv2.warpAffine(img_translation, rotation_matrix, (width, height))\n",
    "    print('Image {}: minimum distance = {:.02f} for a translation of ({}, {}) and an angle = {:.02f}°.'.format(i, dist_final, x_final, y_final, angle_final))\n",
    "    ax[i].axis('off')\n",
    "    ax[i].imshow(img_translated_rotated)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_btw_one_t_r = []\n",
    "\n",
    "# optimal translation for the ones images\n",
    "fig, ax = plt.subplots(1, len(ones_distance_map), figsize=(12, 3))\n",
    "ax[0].imshow(ones_thresholded[0])\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Reference')\n",
    "for i in range(1, len(ones_distance_map)):\n",
    "    height, width = ones_thresholded[i].shape\n",
    "    dist_final = np.inf\n",
    "    x_final = 0\n",
    "    y_final = 0\n",
    "    angle_final = 0\n",
    "    center = (width // 2, height // 2)\n",
    "    \n",
    "    for trans_x in range(-4,5,1):\n",
    "        for trans_y in range(-4,5,1):\n",
    "            \n",
    "            cnt_translation = contour_translation(one_contours[i], trans_x, trans_y)\n",
    "            \n",
    "            for angle in np.arange(0, 360, 15):\n",
    "                \n",
    "                cnt_rotation = contour_rotation(cnt_translation, angle, center)\n",
    "                dist2 = compute_dist(cnt_rotation, one_dist_map)\n",
    "                if dist2 < dist_final:\n",
    "                    dist_final = dist2\n",
    "                    x_final = trans_x\n",
    "                    y_final = trans_y\n",
    "                    angle_final = angle\n",
    "    \n",
    "    distance_btw_one_t_r.append(dist_final)\n",
    "    translation_matrix = np.float32([[1, 0, x_final], [0, 1, y_final]])\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, -angle_final, scale)\n",
    "    img_translation = cv2.warpAffine(ones_thresholded[i], translation_matrix, (width, height))\n",
    "    img_translated_rotated = cv2.warpAffine(img_translation, rotation_matrix, (width, height))\n",
    "    print('Image {}: minimum distance = {:.02f} for a translation of ({}, {}) and an angle = {:.02f}°.'.format(i, dist_final, x_final, y_final, angle_final))\n",
    "    ax[i].axis('off')\n",
    "    ax[i].set_title(\"Image {}\".format(i))\n",
    "    ax[i].imshow(img_translated_rotated)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparaison of results with translation/rotation and without it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_btw_zero = zeros_dist[::2]\n",
    "distance_btw_one = ones_dist[1::2]\n",
    "distance_btw_zero_t_r = distance_btw_zero_t_r\n",
    "distance_btw_one_t_r = distance_btw_one_t_r\n",
    "\n",
    "#Comparison with previous results\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.bar(range(1,10), distance_btw_zero)\n",
    "plt.bar(range(1,10), distance_btw_zero_t_r)\n",
    "plt.legend(['Without trans/rot', 'With trans/rot'])\n",
    "plt.xlabel('Image number')\n",
    "plt.ylabel('Distance')\n",
    "plt.subplot(122)\n",
    "plt.bar(range(1,10), distance_btw_one)\n",
    "plt.bar(range(1,10), distance_btw_one_t_r)\n",
    "plt.legend(['Without trans/rot', 'With trans/rot'])\n",
    "plt.xlabel('Image number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that after finding the optimal translation/rotation, the distance is always equal or smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "The `lab-02-data/part2` folder contains grey-scale pictures of handwritten \"2\" and \"3\".\n",
    "Extract the same feature (typically 2 Fourier descriptors) as in part 1 also on these images and plot them on the same graph as the features of the \"0\" and \"1\".\n",
    "Is it possible to discriminate all these 4 digits with a 2-dimensional feature vector?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load twos\n",
    "twos_path = os.path.join(data_base_path, data_folder, 'part2', '2')\n",
    "twos_names = [nm for nm in os.listdir(twos_path) if '.png' in nm]  # make sure to only load .png\n",
    "twos_names.sort()  # sort file names\n",
    "ic = skimage.io.imread_collection([os.path.join(twos_path, nm) for nm in twos_names])\n",
    "\n",
    "twos_im = skimage.io.concatenate_images(ic)\n",
    "twos_thresholded_tmp = [cv2.threshold(img.copy(), 2, 1, cv2.THRESH_BINARY) for img in twos_im]\n",
    "twos_thresholded = [threshold for _, threshold in twos_thresholded_tmp]\n",
    "del twos_thresholded_tmp\n",
    "\n",
    "#  Load threes\n",
    "threes_path = os.path.join(data_base_path, data_folder, 'part2', '3')\n",
    "threes_names = [nm for nm in os.listdir(threes_path) if '.png' in nm]  # make sure to only load .png\n",
    "threes_names.sort()  # sort file names\n",
    "ic = skimage.io.imread_collection(([os.path.join(threes_path, nm) for nm in threes_names]))\n",
    "\n",
    "threes_im = skimage.io.concatenate_images(ic)\n",
    "threes_thresholded_tmp = [cv2.threshold(img.copy(), 2, 1, cv2.THRESH_BINARY) for img in threes_im]\n",
    "threes_thresholded = [threshold for _, threshold in threes_thresholded_tmp]\n",
    "del threes_thresholded_tmp\n",
    "\n",
    "# Plot images\n",
    "fig, axes = plt.subplots(2, len(twos_im), figsize=(12, 3))\n",
    "for ax, im, nm in zip(axes[0], twos_im, twos_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "for ax, im, nm in zip(axes[1], threes_im, threes_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_contours = []\n",
    "one_contours = []\n",
    "two_contours = []\n",
    "three_contours = []\n",
    "\n",
    "zero_descriptors = []\n",
    "one_descriptors = []\n",
    "two_descriptors = []\n",
    "three_descriptors = []\n",
    "\n",
    "for zero_img, one_img, two_img, three_img in zip(zeros_im, ones_im, twos_im, threes_im):\n",
    "    contour0_raw = find_contour(zero_img, opencv_version)\n",
    "    contour0_complex = convert_contour(contour0_raw)\n",
    "    descriptor0 = find_descriptor(contour0_complex)\n",
    "    \n",
    "    contour1_raw = find_contour(one_img, opencv_version)\n",
    "    contour1_complex = convert_contour(contour1_raw)\n",
    "    descriptor1 = find_descriptor(contour1_complex)\n",
    "    \n",
    "    contour2_raw = find_contour(two_img, opencv_version)\n",
    "    contour2_complex = convert_contour(contour2_raw)\n",
    "    descriptor2 = find_descriptor(contour2_complex)\n",
    "    \n",
    "    contour3_raw = find_contour(three_img, opencv_version)\n",
    "    contour3_complex = convert_contour(contour3_raw)\n",
    "    descriptor3 = find_descriptor(contour3_complex)\n",
    "    \n",
    "    # Save for later usage\n",
    "    zero_contours.append(contour0_raw)\n",
    "    one_contours.append(contour1_raw)\n",
    "    two_contours.append(contour2_raw)\n",
    "    three_contours.append(contour3_raw)\n",
    "    zero_descriptors.append(descriptor0)\n",
    "    one_descriptors.append(descriptor1)\n",
    "    two_descriptors.append(descriptor2)\n",
    "    three_descriptors.append(descriptor3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_coeff = 2\n",
    "zeros_coeff = []\n",
    "ones_coeff = []\n",
    "twos_coeff = []\n",
    "threes_coeff = []\n",
    "\n",
    "MIN_COEFF = 4\n",
    "MAX_COEFF = nb_coeff+MIN_COEFF\n",
    "\n",
    "for zero_descriptor, one_descriptor, two_descriptor, three_descriptor \\\n",
    "    in zip(zero_descriptors, one_descriptors, two_descriptors, three_descriptors):\n",
    "    zeros_coeff.append(np.absolute(zero_descriptor[MIN_COEFF : MAX_COEFF]))\n",
    "    ones_coeff.append(np.absolute(one_descriptor[MIN_COEFF : MAX_COEFF]))\n",
    "    twos_coeff.append(np.absolute(two_descriptor[MIN_COEFF : MAX_COEFF]))\n",
    "    threes_coeff.append(np.absolute(three_descriptor[MIN_COEFF : MAX_COEFF]))\n",
    "\n",
    "plt.scatter(np.asarray(zeros_coeff)[:,0], np.asarray(zeros_coeff)[:,1], color='red', label='zeros descriptors')\n",
    "plt.scatter(np.asarray(ones_coeff)[:,0], np.asarray(ones_coeff)[:,1], color='blue', label='ones descriptors') \n",
    "plt.scatter(np.asarray(twos_coeff)[:,0], np.asarray(twos_coeff)[:,1], color='green', label='twos descriptors')\n",
    "plt.scatter(np.asarray(threes_coeff)[:,0], np.asarray(threes_coeff)[:,1], color='yellow', label='threes descriptors') \n",
    "plt.xlabel(\"Fourrier coefficient 1\")\n",
    "plt.ylabel(\"Fourrier coefficient 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see in the previous plot, it is not possible to separate linearly the 4 categories**  \n",
    "In the following section we will try to see if it possible to separate our data using SVM with a kernel and then we will try to separate them by adding a new dimension (i.e. using 3 fourier descriptors instead of 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC multiclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training dataset from the two fourrier coefficients\n",
    "x_train = np.concatenate((zeros_coeff, ones_coeff, twos_coeff, threes_coeff), axis=0)\n",
    "y_train = np.concatenate((np.zeros(len(zeros_coeff), dtype=int), np.ones(len(ones_coeff), dtype=int),np.ones(len(zeros_coeff), dtype=int)*2,np.ones(len(zeros_coeff),dtype=int)*3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "model = GridSearchCV(SVC(), params_grid, cv=5)\n",
    "model.fit(x_train, y_train)\n",
    "print('Best score for training data: {}'.format(model.best_score_))\n",
    "print('Best C: {}'.format(model.best_estimator_.C))\n",
    "print('Best Kernel: {}'.format(model.best_estimator_.kernel))\n",
    "print('Best Gamma: {}'.format(model.best_estimator_.gamma))\n",
    "final_model = model.best_estimator_\n",
    "print(\"Training set score for SVM: %f\" % final_model.score(x_train , y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plot_decision_regions(x_train, y_train, clf=final_model, legend=2)\n",
    "plt.xlabel(\"Fourrier coefficient 1\")\n",
    "plt.ylabel(\"Fourrier coefficient 2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which Descriptor is used have been determined experimentally by looking how well the data then fitted in the region. We obtained 95% fit with the descriptors indexes 4 and 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVC classification improvement\n",
    "If we want to improve the classification, we need to use 3 descriptors. We can see the result below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_coeff = 3\n",
    "\n",
    "for i in range(6):\n",
    "    MIN_COEFF = i\n",
    "    MAX_COEFF = nb_coeff+MIN_COEFF\n",
    "    zeros_coeff = []\n",
    "    ones_coeff = []\n",
    "    twos_coeff = []\n",
    "    threes_coeff = []\n",
    "    for zero_descriptor, one_descriptor, two_descriptor, three_descriptor \\\n",
    "        in zip(zero_descriptors, one_descriptors, two_descriptors, three_descriptors):\n",
    "        zeros_coeff.append(np.absolute(zero_descriptor[MIN_COEFF : MAX_COEFF]))\n",
    "        ones_coeff.append(np.absolute(one_descriptor[MIN_COEFF : MAX_COEFF]))\n",
    "        twos_coeff.append(np.absolute(two_descriptor[MIN_COEFF : MAX_COEFF]))\n",
    "        threes_coeff.append(np.absolute(three_descriptor[MIN_COEFF : MAX_COEFF]))\n",
    "\n",
    "    # create the training dataset from the two fourrier coefficients\n",
    "    x_train = np.concatenate((zeros_coeff, ones_coeff, twos_coeff, threes_coeff), axis=0)\n",
    "    y_train = np.concatenate((np.zeros(len(zeros_coeff), dtype=int), np.ones(len(ones_coeff), dtype=int),np.ones(len(zeros_coeff), dtype=int)*2,np.ones(len(zeros_coeff),dtype=int)*3), axis=0)\n",
    "\n",
    "    # Create the parameter grid based on the results of random search \n",
    "    params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                         'C': [1, 10, 100, 1000]},\n",
    "                        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "    model = GridSearchCV(SVC(), params_grid, cv=5)\n",
    "    model.fit(x_train, y_train)\n",
    "    final_model = model.best_estimator_\n",
    "    print(\"Training set score for SVM with descriptors range {:d}-{:d} : {:2f}%\".format(MIN_COEFF+1, MAX_COEFF, final_model.score(x_train , y_train)*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous results, we can see that with the descriptors 1, 2 and 3 the classification results in a 100% accuracy  \n",
    "Another thing demonstrated by these results is that the first descriptors are the most representative of the image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
